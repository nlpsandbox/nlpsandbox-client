"""
    NLP Sandbox Data Node API

    # Overview  The NLP Sandbox Data Node is a repository of data used to benchmark NLP Tools like the NLP Sandbox Date Annotator and Person Name Annotator.  The resources that can be stored in this Data Node and the operations supported are listed below:  - Create and manage datasets - Create and manage FHIR stores   - Store and retrieve FHIR patient profiles   - Store and retrieve clinical   notes - Create and manage annotation stores   - Store and retrieve text annotations   # noqa: E501

    The version of the OpenAPI document: 1.0.2
    Contact: thomas.schaffter@sagebionetworks.org
    Generated by: https://openapi-generator.tech
"""


import sys
import unittest

import datanode
from datanode.model.dataset import Dataset
from datanode.model.page_limit import PageLimit
from datanode.model.page_of_datasets_all_of import PageOfDatasetsAllOf
from datanode.model.page_offset import PageOffset
from datanode.model.response_page_metadata import ResponsePageMetadata
from datanode.model.response_page_metadata_links import ResponsePageMetadataLinks
globals()['Dataset'] = Dataset
globals()['PageLimit'] = PageLimit
globals()['PageOfDatasetsAllOf'] = PageOfDatasetsAllOf
globals()['PageOffset'] = PageOffset
globals()['ResponsePageMetadata'] = ResponsePageMetadata
globals()['ResponsePageMetadataLinks'] = ResponsePageMetadataLinks
from datanode.model.page_of_datasets import PageOfDatasets


class TestPageOfDatasets(unittest.TestCase):
    """PageOfDatasets unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def testPageOfDatasets(self):
        """Test PageOfDatasets"""
        # FIXME: construct object with mandatory attributes with example values
        # model = PageOfDatasets()  # noqa: E501
        pass


if __name__ == '__main__':
    unittest.main()
